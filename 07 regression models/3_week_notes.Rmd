---
title: "Regression models lectures 3"
author: "Kirill Setdekov"
date: "August 7, 2019"
output:
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	cache = TRUE
)
```

# week 3

## Multivariable  regression analyses.

If lots of predictors, not one.

The linear model - linear in coefficients
$$Y_i = \sum^p_{k=1}{X_{ik}\beta_j}+\epsilon_i$$

```{r example01}
n = 100
x <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
y <- 1 + x + x2 + x3 + rnorm(n, sd = .1)
ey <- resid(lm(y ~ x2 + x3))
ex <- resid(lm(x ~ x2 + x3))
sum(ey * ex) / sum(ex ^ 2)
coef(lm(ey ~ ex - 1))
coef(lm(y ~ x + x2 + x3))
```

## Fitted values, residuals and residual variation
All of our SLR quantities can be extended to linear models

* Model $Y_i = \sum_{k=1}^p X_{ik} \beta_{k} + \epsilon_{i}$ where $\epsilon_i \sim N(0, \sigma^2)$

* Fitted responses $\hat Y_i = \sum_{k=1}^p X_{ik} \hat \beta_{k}$

* Residuals $e_i = Y_i - \hat Y_i$

* Variance estimate $\hat \sigma^2 = \frac{1}{n-p} \sum_{i=1}^n e_i ^2$

* To get predicted responses at new values, $x_1, \ldots, x_p$, simply plug them into the linear model $\sum_{k=1}^p x_{k} \hat \beta_{k}$

* Coefficients have standard errors, $\hat \sigma_{\hat \beta_k}$, and
$\frac{\hat \beta_k - \beta_k}{\hat \sigma_{\hat \beta_k}}$
follows a $T$ distribution with $n-p$ degrees of freedom.

* Predicted responses have standard errors and we can calculate predicted and expected response intervals.

```{r examples}
require(datasets)
data("swiss")
require(GGally)
require(ggplot2)
ggpairs(swiss, lower = list(continuous = wrap("smooth", method = "loess")))

#fitting all
summary(lm(Fertility~., data = swiss))
summary(lm(Fertility~., data = swiss))$coefficients

#only one result
summary(lm(Fertility~Agriculture, data = swiss))
```

How can adjustment reverse the sign of an effect? Let's try a simulation.
```{r, echo = TRUE}
n <- 100; x2 <- 1 : n; x1 <- .01 * x2 + runif(n, -.1, .1); y = -x1 + x2 + rnorm(n, sd = .01)
summary(lm(y ~ x1))$coef
summary(lm(y ~ x1 + x2))$coef
```

---
```{r changeinsign, echo = FALSE, fig.height=5, fig.width=10, results = 'show'}
par(mfrow = c(1, 2))
plot(
    x1,
    y,
    pch = 21,
    col = "black",
    bg = topo.colors(n)[x2],
    frame = FALSE,
    cex = 1.5
)
title('Unadjusted, color is X2')
abline(lm(y ~ x1), lwd = 2)
plot(
    resid(lm(x1 ~ x2)),
    resid(lm(y ~ x2)),
    pch = 21,
    col = "black",
    bg = "lightblue",
    frame = FALSE,
    cex = 1.5
)
title('Adjusted')
abline(0, coef(lm(y ~ x1 + x2))[2], lwd = 2)
```

## Dummy variables

More than 2 levels

* Consider a multilevel factor level. For didactic reasons, let's say a three level factor (example, US political party affiliation: Republican, Democrat, Independent)

* $Y_i = \beta_0 + X_{i1} \beta_1 + X_{i2} \beta_2 + \epsilon_i$.

* $X_{i1}$ is 1 for Republicans and 0 otherwise.

* $X_{i2}$ is 1 for Democrats and 0 otherwise.

* If $i$ is Republican $E[Y_i] = \beta_0 +\beta_1$

* If $i$ is Democrat $E[Y_i] = \beta_0 + \beta_2$.

* If $i$ is Independent $E[Y_i] = \beta_0$. 

* $\beta_1$ compares Republicans to Independents.

* $\beta_2$ compares Democrats to Independents.

* $\beta_1 - \beta_2$ compares Republicans to Democrats.

* (Choice of reference category changes the interpretation.)

```{r example02}
require(datasets)
data(InsectSprays)
require(stats)
require(graphics)
ggplot(data = InsectSprays, aes(y = count, x = spray, fill = spray)) +
    geom_violin(colour = "black", size = 1) +
    xlab("Type of spray") + ylab("insect count")
# model
summary(lm(count~spray, data = InsectSprays))
#without intercept
summary(lm(count~spray -1, data = InsectSprays))
```
Hardcode dummy - I are instances.
Reference level is "C"
```{r exapmle02hardcode}
summary(lm(count ~
               I(1 * (spray == 'A')) +
               I(1 * (spray == 'B')) +
               I(1 * (spray == 'D')) +
               I(1 * (spray == 'E')) +
               I(1 * (spray == 'F'))
           , data = InsectSprays))

```
Better way to relevel:

```{r exapmle02relevel}
spray2 <- relevel(InsectSprays$spray,"C")
summary(lm(count~spray2, data = InsectSprays))
```

Fitting multiple lines. ANCOVA
```{r example03}
require(datasets)
data("swiss")
hist(swiss$Catholic)
library(dplyr)
swiss <- swiss %>% mutate(CatholicBin = 1 * (Catholic > 50))

g <-
    ggplot(swiss, aes(
        x = Agriculture,
        y = Fertility,
        colour = factor(CatholicBin)
    )) +
    geom_point (size = 4, alpha = 0.75)

g
```

Could mace a factor - with x2 = 1 for CatholicBin

```{r example04simple}
fit <- lm(Fertility ~ Agriculture, data = swiss)
g1 <- g +
    geom_abline(intercept = coef(fit)[1], slope = coef(fit)[2], size = 2)
g1
summary(fit)
```
```{r example04withcatholic}
fit <-
    lm(Fertility ~ Agriculture + factor(CatholicBin), data = swiss)
g1 <- g +
    geom_abline(intercept = coef(fit)[1],
                slope = coef(fit)[2],
                size = 2)
g1 <- g1 +
    geom_abline(
        intercept = coef(fit)[1] + coef(fit)[3],
        slope = coef(fit)[2],
        size = 2
    )
g1
summary(fit)
```

With interaction
```{r example04interaction}
fit <-
    lm(Fertility ~ Agriculture * factor(CatholicBin), data = swiss) #fits all interaction
g1 <- g +
    geom_abline(intercept = coef(fit)[1],
                slope = coef(fit)[2],
                size = 2)
g1 <- g1 +
    geom_abline(
        intercept = coef(fit)[1] + coef(fit)[3],
        slope = coef(fit)[2] + coef(fit)[4],
        size = 2
    )
g1
summary(fit)
```

Adding adjustments

## Consider the following simulated data
Code for the first plot, rest omitted

```{r adjustmentsim}
n <-
    100
t <- rep(c(0, 1), c(n / 2, n / 2))
x <- c(runif(n / 2), runif(n / 2))

beta0 <- 0
beta1 <- 2
tau <- 1
sigma <- .2
y <- beta0 + x * beta1 + t * tau + rnorm(n, sd = sigma)
plot(x, y, type = "n", frame = FALSE)
abline(lm(y ~ x), lwd = 2)
abline(h = mean(y[1:(n / 2)]), lwd = 3)
abline(h = mean(y[(n / 2 + 1):n]), lwd = 3)
fit <- lm(y ~ x + t)
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd = 3)
points(
    x[1:(n / 2)],
    y[1:(n / 2)],
    pch = 21,
    col = "black",
    bg = "lightblue",
    cex = 2
)
points(
    x[(n / 2 + 1):n],
    y[(n / 2 + 1):n],
    pch = 21,
    col = "black",
    bg = "salmon",
    cex = 2
)
```

## Simulation 2
strong marginal effect when disregard effect, very subtle effect if adjust for X
```{r adjustmentsim2, fig.height=5, fig.width=5, echo = FALSE, results='hide'}
n <-
    100
t <-
    rep(c(0, 1), c(n / 2, n / 2))
x <- c(runif(n / 2), 1.5 + runif(n / 2))

beta0 <- 0
beta1 <- 2
tau <- 0
sigma <- .2
y <- beta0 + x * beta1 + t * tau + rnorm(n, sd = sigma)
plot(x, y, type = "n", frame = FALSE)
abline(lm(y ~ x), lwd = 2)
abline(h = mean(y[1:(n / 2)]), lwd = 3)
abline(h = mean(y[(n / 2 + 1):n]), lwd = 3)
fit <- lm(y ~ x + t)
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd = 3)
points(
    x[1:(n / 2)],
    y[1:(n / 2)],
    pch = 21,
    col = "black",
    bg = "lightblue",
    cex = 2
)
points(
    x[(n / 2 + 1):n],
    y[(n / 2 + 1):n],
    pch = 21,
    col = "black",
    bg = "salmon",
    cex = 2
)
```

## Simulation 3 
illustration of simpson's paradox
```{r adjustmentsim3, fig.height=5, fig.width=5, echo = FALSE, results='hide'}
n <-
    100
t <-
    rep(c(0, 1), c(n / 2, n / 2))
x <- c(runif(n / 2), .9 + runif(n / 2))

beta0 <- 0
beta1 <- 2
tau <- -1
sigma <- .2
y <- beta0 + x * beta1 + t * tau + rnorm(n, sd = sigma)
plot(x, y, type = "n", frame = FALSE)
abline(lm(y ~ x), lwd = 2)
abline(h = mean(y[1:(n / 2)]), lwd = 3)
abline(h = mean(y[(n / 2 + 1):n]), lwd = 3)
fit <- lm(y ~ x + t)
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd = 3)
points(
    x[1:(n / 2)],
    y[1:(n / 2)],
    pch = 21,
    col = "black",
    bg = "lightblue",
    cex = 2
)
points(
    x[(n / 2 + 1):n],
    y[(n / 2 + 1):n],
    pch = 21,
    col = "black",
    bg = "salmon",
    cex = 2
)
```

## Simulation 4
no marginal effect, but a huge effect, when adjust for X
```{r adjustmentsim4, fig.height=5, fig.width=5, echo = FALSE, results='hide'}
n <-
    100
t <-
    rep(c(0, 1), c(n / 2, n / 2))
x <- c(.5 + runif(n / 2), runif(n / 2))

beta0 <- 0
beta1 <- 2
tau <- 1
sigma <- .2
y <- beta0 + x * beta1 + t * tau + rnorm(n, sd = sigma)
plot(x, y, type = "n", frame = FALSE)
abline(lm(y ~ x), lwd = 2)
abline(h = mean(y[1:(n / 2)]), lwd = 3)
abline(h = mean(y[(n / 2 + 1):n]), lwd = 3)
fit <- lm(y ~ x + t)
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd = 3)
points(
    x[1:(n / 2)],
    y[1:(n / 2)],
    pch = 21,
    col = "black",
    bg = "lightblue",
    cex = 2
)
points(
    x[(n / 2 + 1):n],
    y[(n / 2 + 1):n],
    pch = 21,
    col = "black",
    bg = "salmon",
    cex = 2
)
```

## Simulation 5
This will be wrong if we think that slopes are equeal - need to have an interaction term
```{r adjustmentsim5, fig.height=5, fig.width=5, echo = FALSE, results='hide'}
n <-
    100
t <-
    rep(c(0, 1), c(n / 2, n / 2))
x <- c(runif(n / 2,-1, 1), runif(n / 2,-1, 1))

beta0 <- 0
beta1 <- 2
tau <- 0
tau1 <- -4
sigma <- .2
y <-
    beta0 + x * beta1 + t * tau + t * x * tau1 + rnorm(n, sd = sigma)
plot(x, y, type = "n", frame = FALSE)
abline(lm(y ~ x), lwd = 2)
abline(h = mean(y[1:(n / 2)]), lwd = 3)
abline(h = mean(y[(n / 2 + 1):n]), lwd = 3)
fit <- lm(y ~ x + t + I(x * t))
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2] + coef(fit)[4], lwd = 3)
points(
    x[1:(n / 2)],
    y[1:(n / 2)],
    pch = 21,
    col = "black",
    bg = "lightblue",
    cex = 2
)
points(
    x[(n / 2 + 1):n],
    y[(n / 2 + 1):n],
    pch = 21,
    col = "black",
    bg = "salmon",
    cex = 2
)
```

### Simulation 6
Binary treatment - not necessary.

```{r adjustmentsim6, fig.height=5, fig.width=5, echo = FALSE, results='hide'}
p <- 1
n <- 100
x2 <- runif(n)
x1 <- p * runif(n) - (1 - p) * x2
beta0 <- 0
beta1 <- 1
tau <- 4
sigma <- .01
y <- beta0 + x1 * beta1 + tau * x2 + rnorm(n, sd = sigma)
plot(x1, y, type = "n", frame = FALSE)
abline(lm(y ~ x1), lwd = 2)
co.pal <- heat.colors(n)
points(
    x1,
    y,
    pch = 21,
    col = "black",
    bg = co.pal[round((n - 1) * x2 + 1)],
    cex = 2
)
```

Need to look in 3d

```{r adjustmentsim63d}
library(rgl)
plot3d(x1, x2, y)
```
Better to look at residuals
Strong relationsip between Y and X2
```{r resuduals, fig.height=5, fig.width=5, echo = FALSE, results='hide'}
plot(
    resid(lm(x1 ~ x2)),
    resid(lm(y ~ x2)),
    frame = FALSE,
    col = "black",
    bg = "lightblue",
    pch = 21,
    cex = 2
)
abline(lm(I(resid(lm(
    x1 ~ x2
))) ~ I(resid(lm(
    y ~ x2
)))), lwd = 2)
```