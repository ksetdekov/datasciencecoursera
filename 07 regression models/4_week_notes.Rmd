---
title: "Regression models lectures 4"
author: "Kirill Setdekov"
date: "September 6, 2019"
output:
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	cache = TRUE
)
```

# week 4

swirl

10. Variance Inflation Factors
11. Overfitting and Underfitting
12. Binary Outcomes
13. Count Outcomes


VIF is the square of standard error inflation.

anova to assess the significance of the two added regressors
The three asterisks, ***, at the lower right of the printed table indicate that the null hypothesis is rejected at the 0.001 level, so at
| least one of the two additional regressors is significant

`anova(fit1, fit3)`
but 
Model residuals should be tested for normality.
normality test
shapiro.test(fit3$residuals)


deviance(model), calculates the residual sum of squares

`all.equal(lhs,rhs)`
var(data)=var(estimate)+var(residuals)

## binary results
logit model, logistic regression
$log(p/(1-p)) = b0 + b1*score$ . The link function, $log(p/(1-p))$

## count outcomes
Poisson process

http://jtleek.com/codedata.html

class test `class(hits[,'date'])`

` mdl <- glm(visits ~ date, poisson, hits)`
poisson regression - result is a number

confidence interval vor logit regression
`exp(confint(mdl,'date'))`

offset
`mdl2 <- glm(formula = simplystats ~ date, family = poisson, data = hits, offset = log(visits + 1))`

#Lectures
Logistic regression
Binomial random variables and binary

```{r loadRavens,cache=TRUE}
load("./ravensData.rda")
head(ravensData)
```

__Log odds $(-\infty,\infty)$__

$$\ln\left(\frac{\rm{Pr}(RW_i | RS_i, b_0, b_1 )}{1-\rm{Pr}(RW_i | RS_i, b_0, b_1)}\right)$$ 
$$Odds=\frac{p}{1-p} $$
$$P=\frac{Odds}{1-Odds} $$
logit == log of the odds.


__Logistic__

$$ \rm{Pr}(RW_i | RS_i, b_0, b_1) = \frac{\exp(b_0 + b_1 RS_i)}{1 + \exp(b_0 + b_1 RS_i)}$$

or

$$ \ln\left(\frac{\rm{Pr}(RW_i | RS_i, b_0, b_1 )}{1-\rm{Pr}(RW_i | RS_i, b_0, b_1)}\right) = b_0 + b_1 RS_i $$
$b_0$ - Log odds of a Ravens win if they score zero points
$$\frac{exp(b_0)}{1-exp(b_0)} = probability of winnin with 0 points$$
$b_1$ - Log odds ratio of win probability for each point scored (compared to zero points)

$exp(b_1)$ ration of increase per 1 point

## Ravens logistic regression

```{r logReg, dependson = "loadRavens"}
logRegRavens <-
    glm(ravensData$ravenWinNum ~ ravensData$ravenScore, family = "binomial")
summary(logRegRavens)
```

## Ravens fitted values

```{r dependson = "logReg",fig.height=4,fig.width=4}
plot(ravensData$ravenScore,logRegRavens$fitted,pch=19,col="blue",xlab="Score",ylab="Prob Ravens Win")
```

## Odds ratios and confidence intervals

```{r dependson = "logReg",fig.height=4,fig.width=4}
exp(logRegRavens$coeff)

## 11% increase per score
exp(confint(logRegRavens))  ##- odds ratio
```


confidence interval - includes 1, increase in score is not significant

## ANOVA for logistic regression

```{r dependson = "logReg",fig.height=4,fig.width=4}
anova(logRegRavens,test="Chisq")
```

### Interpreting Odds Ratios

* Not probabilities 
* Odds ratio of 1 = no difference in odds
* Log odds ratio of 0 = no difference in odds
* Odds ratio < 0.5 or > 2 commonly a "moderate effect"
* Relative risk $\frac{\rm{Pr}(RW_i | RS_i = 10)}{\rm{Pr}(RW_i | RS_i = 0)}$ often easier to interpret, harder to estimate
* For small probabilities RR $\approx$ OR but __they are not the same__!

* [Open Intro Chapter on Logistic Regression](http://www.openintro.org/stat/down/oiStat2_08.pdf)

# poisson GLM

* Many data take the form of counts
  * Calls to a call center
  * Number of flu cases in an area
  * Number of cars that cross a bridge
* Data may also be in the form of rates
  * Percent of children passing a test
  * Percent of hits to a website from a country
* Linear regression with transformation is an option

Useful for counts and rates.

## The Poisson mass function
- $X \sim Poisson(t\lambda)$ if
$$
P(X = x) = \frac{(t\lambda)^x e^{-t\lambda}}{x!}
$$
For $x = 0, 1, \ldots$.
- The mean of the Poisson is $E[X] = t\lambda$, thus $E[X / t] = \lambda$
- The variance of the Poisson is $Var(X) = t\lambda$.
- The Poisson tends to a normal as $t\lambda$ gets large.

Mean and variance are equal.

* Since the unit of time is always one day, set $t = 1$ and then
the Poisson mean is interpretted as web hits per day. (If we set $t = 24$, it would
be web hits per hour).


```{r leekLoad,cache=TRUE}
load("./gaData.rda")
library(ggplot2)
gaData$julian <- julian(gaData$date)
head(gaData)
```

```{r, dependson="leekLoad",fig.height=4.5,fig.width=4.5}
qplot(julian, visits, data=gaData)
```
```{r linReg, dependson="leekLoad",fig.height=4,fig.width=4, cache=TRUE}
plot(gaData$julian,gaData$visits,pch=19,col="darkgrey",xlab="Julian",ylab="Visits")
lm1 <- lm(gaData$visits ~ gaData$julian)
abline(lm1,col="red",lwd=3)
```

add a log of hits

- When you take the natural log of outcomes and fit a regression model, your exponentiated coefficients
estimate things about geometric means.
- $e^{\beta_0}$ estimated geometric mean hits on day 0
- $e^{\beta_1}$ estimated relative increase or decrease in geometric mean hits per day
- There's a problem with logs with you have zero counts, adding a constant works
```{r}
round(exp(coef(lm(I(log(gaData$visits + 1)) ~ gaData$julian))), 5)
```

## Linear vs. Poisson regression

__Linear__

$$ NH_i = b_0 + b_1 JD_i + e_i $$

or

$$ E[NH_i | JD_i, b_0, b_1] = b_0 + b_1 JD_i$$

__Poisson/log-linear__

$$ \log\left(E[NH_i | JD_i, b_0, b_1]\right) = b_0 + b_1 JD_i $$

or

$$ E[NH_i | JD_i, b_0, b_1] = \exp\left(b_0 + b_1 JD_i\right) $$


## Poisson regression in R

```{r poisReg, dependson="linReg",fig.height=4.5,fig.width=4.5, cache=TRUE}
plot(gaData$julian,gaData$visits,pch=19,col="darkgrey",xlab="Julian",ylab="Visits")
glm1 <- glm(gaData$visits ~ gaData$julian,family="poisson")
abline(lm1,col="red",lwd=3); lines(gaData$julian,glm1$fitted,col="blue",lwd=3)
```

## Model agnostic standard errors 

```{r agnostic}
library(sandwich)
confint.agnostic <- function (object, parm, level = 0.95, ...)
{
    cf <- coef(object); pnames <- names(cf)
    if (missing(parm))
        parm <- pnames
    else if (is.numeric(parm))
        parm <- pnames[parm]
    a <- (1 - level)/2; a <- c(a, 1 - a)
    pct <- stats:::format.perc(a, 3)
    fac <- qnorm(a)
    ci <- array(NA, dim = c(length(parm), 2L), dimnames = list(parm,
                                                               pct))
    ses <- sqrt(diag(sandwich::vcovHC(object)))[parm]
    ci[] <- cf[parm] + ses %o% fac
    ci
}
```
[http://stackoverflow.com/questions/3817182/vcovhc-and-confidence-interval](http://stackoverflow.com/questions/3817182/vcovhc-and-confidence-interval)

---

## Estimating confidence intervals

```{r}
confint(glm1)
confint.agnostic(glm1)
```

Rates.
Hitsfromstat/allhits
$$ \log\left(E[NHSS_i | JD_i, b_0, b_1]\right) = \log(Totalhits_i) + b_0 + b_1 JD_i $$
```{r ratesFit,dependson="agnostic", cache=TRUE,fig.height=4,fig.width=4}
glm2 <-
    glm(
        gaData$simplystats ~ julian(gaData$date),
        offset = log(visits + 1), #+1 because take log of 0
        family = "poisson",
        data = gaData
    )
plot(
    julian(gaData$date),
    glm2$fitted,
    col = "blue",
    pch = 19,
    xlab = "Date",
    ylab = "Fitted Counts"
)
points(julian(gaData$date),
       glm1$fitted,
       col = "red",
       pch = 19)
#basically rates are blue points devided by red line
##rates
plot(
    julian(gaData$date),
    gaData$simplystats / (gaData$visits + 1),
    col = "grey",
    xlab = "Date",
    ylab = "Fitted Rates",
    pch = 19
)
lines(
    julian(gaData$date),
    glm2$fitted / (gaData$visits + 1),
    col = "blue",
    lwd = 3
)
```
## More information
zero inflation - lots of zeros not randomly in the dataset (e.g. in the beginning)
* [pscl package](http://cran.r-project.org/web/packages/pscl/index.html) - the function _zeroinfl_ fits zero inflated models. 



#Quiz
1. -0.031 - coefficient wrong

```{r quiz1}
library(MASS)
?shuttle

mdl <- glm(use~wind, binomial, shuttle)
summary(mdl)
exp(mdl$coefficients)
```
 2. 1.485 wrong
 
```{r quiz2}
mdl2 <- glm(use~wind+magn, binomial, shuttle)

summary(mdl2)

```

3. The coefficients reverse their signs. right

4. Consider the insect spray data \verb|InsectSprays|InsectSprays. Fit a Poisson model using spray as a factor level. Report the estimated relative rate comapring spray A (numerator) to spray B (denominator).
-0.05588 wrong

```{r quiz4}
library(datasets)
?InsectSprays

mdl4 <- glm(formula = count ~ spray, family = poisson, data = InsectSprays)
summary(mdl4)

-0.05588
```
5. The coefficient estimate is multiplied by 10. wrong

6. 1.01307 right
```{r quiz6}
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
plot(x,y)
library(lspline)
m1 <- lm(y ~ lspline(x, c(0)))
summary(m1)
```


